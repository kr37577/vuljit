# Replication Package

This repository provides the replication package for our research paper. It contains the datasets, scripts, and instructions necessary to reproduce the experimental results reported in the paper.

> **Paper**: *[Paper Title]* (to appear / published at [Venue, Year])  
> **Authors**: [Author Names]  
> **DOI / Preprint**: [Link]

---

## Table of Contents

1. [Overview](#overview)
2. [Requirements](#requirements)
3. [Setup](#setup)
4. [Repository Structure](#repository-structure)
5. [Reproducing the Experiments](#reproducing-the-experiments)
6. [Expected Results](#expected-results)
7. [License](#license)

---

## Overview

<!-- Brief (2-3 sentences) description of what the paper studies and what this package reproduces. -->

This package allows you to:

- Prepare the dataset used in our study
- Extract and aggregate software metrics
- Train cross-project prediction models
- Generate the results for RQ1, RQ2, and RQ3

---

## Requirements

| Item | Version / Note |
|------|----------------|
| **OS** | Linux (tested on Ubuntu 22.04) |
| **Python** | 3.12.3 |
| **Disk Space** | ~3 TB |
| **Runtime** | Several days to weeks (SLURM cluster recommended) |
| **Chrome / Chromium** | Required for `osv_monorail_selenium.py` |
| **ChromeDriver** | Must match your Chrome version |

All Python dependencies are listed in `requirements.txt`.

### Note on Selenium-based Scripts

The script `scripts/data_acquisition/osv_monorail_selenium.py` requires a GUI browser (Chrome/Chromium) and is **recommended to run on a local PC** rather than a headless server or cluster environment.

If you must run it on a server, ensure:
- Chrome is installed with headless mode support
- ChromeDriver version matches the installed Chrome
- X virtual framebuffer (Xvfb) is available if needed

## Setup

```bash
# 1. Verify Python version
python3 --version   # should be 3.12.x

# 2. Create and activate a virtual environment
python3 -m venv .venv
source .venv/bin/activate

# 3. Install dependencies
pip install -r requirements.txt
```

### External Data

We use [OSS-Fuzz](https://github.com/google/oss-fuzz). The scripts automatically clone the repository at the following commit:

```
96cf5fd552e90b1879d5d3c9bf6d9cdb95e6f122
```

---

## Repository Structure

```
.
├── README                # This file
├── requirements.txt      # Python dependencies
├── run_all_process.sh    # One-click replication script
├── datasets/             # Raw and derived datasets
├── replication/          # Step-by-step scripts
│   ├── data_acquisition.sh
│   ├── ossfuzz_clone_and_analyze.sh
│   ├── metrics_extraction.sh
│   ├── aggregate_metrics_pipeline.sh
│   ├── cross_project_prediction.sh
│   ├── RQ1_2.sh
│   └── RQ3.sh
├── scripts/              # scripts
└── analysis/             # Analysis outputs
```

---

## Reproducing the Experiments

### Quick Start (Recommended)

Run all steps sequentially from the project root:

```bash
bash run_all_process.sh
```

### Step-by-Step Execution

```bash
cd replication

# Step 1: Data acquisition
bash data_acquisition.sh

# Step 2: Clone OSS-Fuzz and analyze builds
bash ossfuzz_clone_and_analyze.sh

# Step 3: Extract metrics
bash metrics_extraction.sh

# Step 4: Aggregate metrics
bash aggregate_metrics_pipeline.sh

# Step 5: Train cross-project prediction models
bash cross_project_prediction.sh

# Step 6: Generate RQ1/RQ2 results
bash RQ1_2.sh

# Step 7: Run RQ3 simulation
bash RQ3.sh
```

> **Note**: Some scripts require substantial time and resources. We strongly recommend running them on a SLURM-managed cluster.

---

## Expected Results

<!-- Describe where the outputs are stored and what files the reader should expect. -->

After successful execution, results will be located in:

| Research Question | Output Path |
|-------------------|-------------|
| RQ1 / RQ2 | `analysis/research_question1_2/` |
| RQ3 | `analysis/research_question3/` |

---

## License

<!-- Specify the license, e.g., MIT, Apache 2.0, CC BY 4.0 for data, etc. -->

This project is licensed under the [MIT License](LICENSE).

